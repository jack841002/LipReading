{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "import imutils\n",
    "import gc\n",
    "from sklearn.utils import shuffle, Sequence\n",
    "import random\n",
    "label_max_len = 37\n",
    "minibatch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        if char >= 'a' and char <= 'z':\n",
    "            ret.append(ord(char) - ord('a'))\n",
    "        elif char == ' ':\n",
    "            ret.append(26)\n",
    "    return ret\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    # 26 is space, 27 is CTC blank char\n",
    "    text = ''\n",
    "    for c in labels:\n",
    "        if c >= 0 and c < 26:\n",
    "            text += chr(c + ord('a'))\n",
    "        elif c == 26:\n",
    "            text += ' '\n",
    "    return text\n",
    "\n",
    "def get_padded_label(label):\n",
    "    padding = np.ones((label_max_len-len(label))) * 28        # -1  \n",
    "    return np.concatenate((np.array(label), padding), axis=0)\n",
    "\n",
    "# def get_unpadded_label(label):\n",
    "#     padding = np.ones((0)) * -1\n",
    "#     return np.concatenate((np.array(label), padding), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_unseen_train = np.load('./data_split/unseen/image_unseen_train.npy')\n",
    "image_unseen_val = np.load('./data_split/unseen/image_unseen_val.npy')\n",
    "\n",
    "f_val = open('./data_split/unseen/correct_txt_unseen_val.txt')\n",
    "txt_unseen_val = []\n",
    "for line in f_val:\n",
    "    line = line.strip('\\n')\n",
    "    txt_unseen_val.append(line)\n",
    "    \n",
    "f_train = open('./data_split/unseen/correct_txt_unseen_train.txt')\n",
    "txt_unseen_train = []\n",
    "for line in f_train:\n",
    "    line = line.strip('\\n')\n",
    "    txt_unseen_train.append(line)\n",
    "    \n",
    "train_label_length = []\n",
    "train_input_length = []\n",
    "for i in txt_unseen_train:\n",
    "    train_label_length.append(len(i))\n",
    "    train_input_length.append(75)\n",
    "    \n",
    "val_label_length = []\n",
    "val_input_length = []\n",
    "for i in txt_unseen_val:\n",
    "    val_label_length.append(len(i))\n",
    "    val_input_length.append(75)\n",
    "    \n",
    "train_label_length = np.array(train_label_length)\n",
    "train_input_length = np.array(train_input_length)\n",
    "val_label_length = np.array(val_label_length)\n",
    "val_input_length = np.array(val_input_length)\n",
    "txt_unseen_train = np.array(txt_unseen_train)\n",
    "txt_unseen_val = np.array(txt_unseen_val)\n",
    "\n",
    "print(image_unseen_train.shape, txt_unseen_train.shape)\n",
    "print(image_unseen_val.shape, txt_unseen_val.shape)\n",
    "print(train_label_length.shape, train_input_length.shape)\n",
    "print(val_label_length.shape, val_input_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_gen(data, data_label, input_length, label_length, minibatch_size):  # 定义batch数据生成器\n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx + minibatch_size>=len(data_label):\n",
    "            idx=0\n",
    "#             randnum = random.randint(0,100)\n",
    "#             random.seed(randnum)\n",
    "#             random.shuffle(data)\n",
    "#             random.seed(randnum)\n",
    "#             random.shuffle(data_label)\n",
    "#             random.seed(randnum)\n",
    "#             random.shuffle(input_length)\n",
    "#             random.seed(randnum)\n",
    "#             random.shuffle(label_length)\n",
    "\n",
    "#             data,data_label,input_length,label_length = shuffle(data,data_label,input_length,label_length\n",
    "#                                                                 ,random_state=13)\n",
    "        \n",
    "        start = idx\n",
    "        idx += minibatch_size\n",
    "        batch_data = []\n",
    "        batch_data = data[start:start+minibatch_size]\n",
    "\n",
    "        batch_label = []\n",
    "#         batch_label = data_label[start:start+minibatch_size]\n",
    "        for index in data_label[start:start+minibatch_size]:\n",
    "            temp = text_to_labels(index)\n",
    "            temp = get_padded_label(temp)\n",
    "#             temp = get_unpadded_label(temp)\n",
    "            batch_label.append(temp)\n",
    "        batch_label = np.array(batch_label)\n",
    "        \n",
    "        batch_input_length = []\n",
    "        batch_input_length = input_length[start:start+minibatch_size]\n",
    "        batch_label_length = []\n",
    "        batch_label_length = label_length[start:start+minibatch_size]\n",
    "        \n",
    "        # 畫素資料浮點化以便歸一化\n",
    "        batch_data = batch_data.astype('float32')\n",
    "        batch_data /= 255\n",
    "        \n",
    "        inputs = {'the_input': batch_data,\n",
    "                  'the_labels': batch_label,\n",
    "                  'input_length': batch_input_length,\n",
    "                  'label_length': batch_label_length}\n",
    "        outputs = {'ctc': np.zeros([minibatch_size])}\n",
    "        \n",
    "        yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch_gen(data, data_label, input_length, label_length, minibatch_size):  # 定义batch数据生成器\n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx + minibatch_size>=len(data_label):\n",
    "            idx=0\n",
    "        \n",
    "        start = idx\n",
    "        idx += minibatch_size\n",
    "        batch_data = []\n",
    "        batch_data = data[start:start+minibatch_size]\n",
    "        \n",
    "        batch_label = []\n",
    "#         batch_label = data_label[start:start+minibatch_size]\n",
    "        for index in data_label[start:start+minibatch_size]:\n",
    "            temp = text_to_labels(index)\n",
    "            temp = get_padded_label(temp)\n",
    "#             temp = get_unpadded_label(temp)\n",
    "            batch_label.append(temp)\n",
    "        batch_label = np.array(batch_label)\n",
    "         \n",
    "        batch_input_length = []\n",
    "        batch_input_length = input_length[start:start+minibatch_size]\n",
    "        batch_label_length = []\n",
    "        batch_label_length = label_length[start:start+minibatch_size]\n",
    "        \n",
    "        # 畫素資料浮點化以便歸一化\n",
    "        batch_data = batch_data.astype('float32')\n",
    "        batch_data /= 255\n",
    "        \n",
    "        inputs = {'the_input': batch_data,\n",
    "                  'the_labels': batch_label,\n",
    "                  'input_length': batch_input_length,\n",
    "                  'label_length': batch_label_length}\n",
    "        outputs = {'ctc': np.zeros([minibatch_size])}\n",
    "        \n",
    "        yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, SpatialDropout3D\n",
    "from keras.layers import Convolution3D, MaxPooling3D\n",
    "from keras.layers.convolutional import Conv3D, ZeroPadding3D\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from multiprocessing import set_start_method, Pool\n",
    "set_start_method('forkserver')\n",
    "from decoders import Decoder\n",
    "from callbacks import Statistics, Visualize\n",
    "from spell import Spell\n",
    "# from error_rates import ErrorRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # From Keras example image_ocr.py:\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    # y_pred = y_pred[:, 2:, :]\n",
    "    y_pred = y_pred[:, :, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "def CTC(name, args):\n",
    "    return Lambda(ctc_lambda_func, output_shape=(1,), name=name)(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipNet(object):\n",
    "    def __init__(self, img_c=3, img_w=100, img_h=50, frames_n=75, absolute_max_string_len=37, output_size=28):\n",
    "        self.img_c = img_c\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.frames_n = frames_n\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "        self.output_size = output_size\n",
    "        self.build()\n",
    "    \n",
    "    def build(self):\n",
    "        self.input_data = Input(name='the_input', shape=(75,50,100,3), dtype='float32')\n",
    "        \n",
    "        self.zero1 = ZeroPadding3D(padding=(1, 2, 2), name='zero1')(self.input_data)\n",
    "        self.conv1 = Conv3D(32, (3, 5, 5), strides=(1, 2, 2), kernel_initializer='he_normal', name='conv1')(self.zero1)\n",
    "        self.batc1 = BatchNormalization(name='batc1')(self.conv1)\n",
    "        self.actv1 = Activation('relu', name='actv1')(self.batc1)\n",
    "        self.drop1 = SpatialDropout3D(0.5)(self.actv1)\n",
    "        self.maxp1 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')(self.drop1)\n",
    "\n",
    "        self.zero2 = ZeroPadding3D(padding=(1, 2, 2), name='zero2')(self.maxp1)\n",
    "        self.conv2 = Conv3D(64, (3, 5, 5), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv2')(self.zero2)\n",
    "        self.batc2 = BatchNormalization(name='batc2')(self.conv2)\n",
    "        self.actv2 = Activation('relu', name='actv2')(self.batc2)\n",
    "        self.drop2 = SpatialDropout3D(0.5)(self.actv2)\n",
    "        self.maxp2 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')(self.drop2)\n",
    "\n",
    "        self.zero3 = ZeroPadding3D(padding=(1, 1, 1), name='zero3')(self.maxp2)\n",
    "        self.conv3 = Conv3D(96, (3, 3, 3), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv3')(self.zero3)\n",
    "        self.batc3 = BatchNormalization(name='batc3')(self.conv3)\n",
    "        self.actv3 = Activation('relu', name='actv3')(self.batc3)\n",
    "        self.drop3 = SpatialDropout3D(0.5)(self.actv3)\n",
    "        self.maxp3 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')(self.drop3)\n",
    "\n",
    "        self.resh1 = TimeDistributed(Flatten())(self.maxp3)\n",
    "\n",
    "        self.gru_1 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat')(self.resh1)\n",
    "        self.gru_2 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'), merge_mode='concat')(self.gru_1)\n",
    "\n",
    "        # transforms RNN output to character activations:\n",
    "        self.dense1 = Dense(self.output_size, kernel_initializer='he_normal', name='dense1')(self.gru_2)\n",
    "\n",
    "        self.y_pred = Activation('softmax', name='softmax')(self.dense1)\n",
    "\n",
    "        self.labels = Input(name='the_labels', shape=[self.absolute_max_string_len], dtype='float32')\n",
    "        self.input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        self.label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "        self.loss_out = CTC('ctc', [self.y_pred, self.labels, self.input_length, self.label_length])\n",
    "\n",
    "        self.model = Model(inputs=[self.input_data, self.labels, self.input_length, self.label_length], outputs=self.loss_out)\n",
    "        \n",
    "    def summary(self):\n",
    "        Model(inputs=self.input_data, outputs=self.y_pred).summary()\n",
    "\n",
    "    def predict(self, input_batch):\n",
    "        return self.test_function([input_batch, 0])[0]  # the first 0 indicates test\n",
    "\n",
    "    @property\n",
    "    def test_function(self):\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        return K.function([self.input_data, K.learning_phase()], [self.y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipnet = LipNet(img_c=3, img_w=100, img_h=50, frames_n=75, absolute_max_string_len=label_max_len, output_size=28)\n",
    "lipnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "lipnet.model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复模型结构及权重\n",
    "# lipnet.model.load_weights('./weight/368-overlap-2.h5')\n",
    "lipnet.model.load_weights('./weight/unseen-weights178.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Spell('./grid1.txt')\n",
    "decoder = Decoder(greedy=False,beam_width=200,postprocessors=[labels_to_text,spell.sentence])\n",
    "statistics  = Statistics(lipnet, val_batch_gen(image_unseen_val, txt_unseen_val, val_input_length, val_input_length, 50), decoder, 256)\n",
    "# visualize = Visualize('./unseen_visual', lipnet, val_batch_gen(image_unseen_val, txt_unseen_val, val_input_length, val_input_length, minibatch_size)\n",
    "#                      , decoder, num_display_sentences=minibatch_size)\n",
    "# error_rates = ErrorRates(lipnet, val_batch_gen(image_unseen_val, txt_unseen_val, val_input_length, val_input_length, 50), decoder, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipnet.model.fit_generator(generator = train_batch_gen(image_unseen_train, txt_unseen_train, train_input_length, train_label_length, minibatch_size),\n",
    "                        steps_per_epoch = int(len(image_unseen_train)/minibatch_size), epochs = 5,\n",
    "                        validation_data = val_batch_gen(image_unseen_val, txt_unseen_val, val_input_length, val_input_length, minibatch_size), \n",
    "                        validation_steps = int(len(image_unseen_val)/minibatch_size),\n",
    "                        callbacks = [statistics],\n",
    "                        initial_epoch = 0,\n",
    "                        verbose=1,\n",
    "                        max_q_size=5,\n",
    "                        workers=0,\n",
    "#                         pickle_safe=True,\n",
    "#                         shuffle=True,\n",
    "                        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型结构及权重\n",
    "lipnet.model.save('./weight/178-unseen-5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复模型结构及权重\n",
    "# lipnet.model.load_weights('./weight/368-overlap-6.h5')\n",
    "lipnet.model.load_weights('./weight/178-unseen-6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicts(data, input_length):\n",
    "    batch_data = []\n",
    "    batch_data = data[495:505]\n",
    "    \n",
    "    # 畫素資料浮點化以便歸一化\n",
    "    batch_data = batch_data.astype('float32')\n",
    "    batch_data /= 255\n",
    "    \n",
    "    batch_input_length = []\n",
    "    batch_input_length = input_length[495:505]\n",
    "    \n",
    "    return (batch_data, batch_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data, pred_input_length = predicts(image_unseen_val, val_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lipnet.predict(pred_data)\n",
    "# y_predy_pred\n",
    "result = decoder.decode(y_pred, pred_input_length)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(txt_unseen_val[495:505])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
