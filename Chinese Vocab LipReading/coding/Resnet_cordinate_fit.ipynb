{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "import imutils\n",
    "import gc\n",
    "from sklearn.utils import shuffle\n",
    "from os.path import join\n",
    "from keras.utils.np_utils import *\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "minibatch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斷詞\n",
    "vocab_200 = open('./split_data/words.txt', encoding='UTF-8-sig')\n",
    "split_word = []\n",
    "for line in vocab_200:\n",
    "    line = line.strip('\\n')\n",
    "    split_word.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做字典\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok_path = join('split_data', 'vocabulary_tok.pickle')\n",
    "\n",
    "# saving\n",
    "if not os.path.exists(tok_path):\n",
    "    tok = Tokenizer(char_level=False)\n",
    "    tok.fit_on_texts(split_word)\n",
    "    with open(tok_path, 'wb') as handle:\n",
    "        pickle.dump(tok, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        print('create tok')\n",
    "# loading\n",
    "else:\n",
    "    with open(tok_path, 'rb') as handle:\n",
    "        tok = pickle.load(handle)\n",
    "        print('load tok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tok.word_index))          # 詞彙的個數    1~200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ii,iterm in enumerate(tok.word_index.items()):\n",
    "#     print(iterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_text(label):                       # label is list\n",
    "    words = tok.sequences_to_texts([[label[0]+1]])\n",
    "    text = words[0]\n",
    "    return(text)\n",
    "\n",
    "def text_to_labels(text):                        # text is string\n",
    "    seq = tok.texts_to_sequences([text])\n",
    "    seq = seq[0][0] - 1\n",
    "    return(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = np.load('./split_data/image_cordinate/image_bright_train.npy')\n",
    "image_val = np.load('./split_data/image_cordinate/image_bright_val.npy')\n",
    "\n",
    "f_val = open('./split_data/image_cordinate/txt_bright_cord_val.txt', encoding='UTF-8-sig')\n",
    "txt_val = []\n",
    "for line in f_val:\n",
    "    line = line.strip('\\n')\n",
    "    txt_val.append(line)\n",
    "    \n",
    "f_train = open('./split_data/image_cordinate/txt_bright_cord_train.txt', encoding='UTF-8-sig')\n",
    "txt_train = []\n",
    "for line in f_train:\n",
    "    line = line.strip('\\n')\n",
    "    txt_train.append(line)\n",
    "    \n",
    "txt_train = np.array(txt_train)\n",
    "txt_val = np.array(txt_val)\n",
    "\n",
    "print(image_train.shape, len(txt_train))\n",
    "print(image_val.shape, len(txt_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train = image_train.astype('float32')\n",
    "# image_val = image_val.astype('float32') \n",
    "\n",
    "image_train /= 255\n",
    "image_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = []\n",
    "for index1 in txt_train:\n",
    "    temp = text_to_labels(index1)\n",
    "    label_train.append(temp)\n",
    "label_train = np.array(label_train)\n",
    "label_train = to_categorical(label_train, 200)\n",
    "\n",
    "label_val = []\n",
    "for index1 in txt_val:\n",
    "    temp = text_to_labels(index1)\n",
    "    label_val.append(temp)\n",
    "label_val = np.array(label_val)\n",
    "label_val = to_categorical(label_val, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_train = np.load('./split_data/image_cordinate/cord_train.npy')\n",
    "cord_val = np.load('./split_data/image_cordinate/cord_val.npy')\n",
    "\n",
    "print(cord_train.shape)\n",
    "print(cord_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算兩張img的座標差\n",
    "Subtraction = []\n",
    "for oneData in cord_train:\n",
    "    for num in range(len(oneData)-1):\n",
    "        num1 = num + 1\n",
    "        sub = oneData[num1] - oneData[num]\n",
    "        Subtraction.append(sub)\n",
    "cord_train = np.array(Subtraction).reshape((-1, 76, 20, 2))\n",
    "\n",
    "Subtraction = []\n",
    "for oneData in cord_val:\n",
    "    for num in range(len(oneData)-1):\n",
    "        num1 = num + 1\n",
    "        sub = oneData[num1] - oneData[num]\n",
    "        Subtraction.append(sub)\n",
    "cord_val = np.array(Subtraction).reshape((-1, 76, 20, 2))\n",
    "\n",
    "print(cord_train.shape)\n",
    "print(cord_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim 4 to 3\n",
    "cord_train = cord_train.reshape((len(cord_train), 76, -1))\n",
    "cord_val = cord_val.reshape((len(cord_val), 76, -1))\n",
    "print(cord_train.shape)\n",
    "print(cord_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_ScoreNormalization(data):\n",
    "    z_score = []\n",
    "    z_scaler = preprocessing.StandardScaler()\n",
    "    for i in data:\n",
    "        iris_z = z_scaler.fit_transform(i)\n",
    "        z_score.append(iris_z)\n",
    "    return(np.array(z_score))\n",
    "\n",
    "cord_train = Z_ScoreNormalization(cord_train)\n",
    "cord_val = Z_ScoreNormalization(cord_val)\n",
    "print(cord_train.shape)\n",
    "print(cord_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_train = cord_train.astype('float32')\n",
    "cord_val = cord_val.astype('float32') \n",
    "\n",
    "# image_train /= 255\n",
    "# image_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, SpatialDropout3D\n",
    "from keras.layers import Convolution3D, MaxPooling3D, LSTM, Conv2D, AveragePooling3D\n",
    "from keras.layers.convolutional import Conv3D, ZeroPadding3D\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from multiprocessing import set_start_method, Pool\n",
    "set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define convolution with batchnromalization\n",
    "def Conv3d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1,1),name=None):\n",
    "    x = Conv3D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "#Define Residual Block for ResNet34(2 convolution layers)\n",
    "def Residual_Block(input_model,nb_filter,kernel_size,strides=(1,1,1), with_conv_shortcut =False):\n",
    "    x = Conv3d_BN(input_model,nb_filter=nb_filter,kernel_size=kernel_size,strides=strides,padding='same')\n",
    "    x = Conv3d_BN(x, nb_filter=nb_filter, kernel_size=kernel_size,padding='same')\n",
    "    \n",
    "    #need convolution on shortcut for add different channel\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv3d_BN(input_model,nb_filter=nb_filter,strides=strides,kernel_size=kernel_size)\n",
    "        x = layers.add([x,shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = layers.add([x,input_model])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "# help(TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(object):\n",
    "    def __init__(self, img_c=3, img_w=100, img_h=50, cord=40, frames_n=77, frames_cord=76, output_size=len(tok.word_index)):\n",
    "        self.img_c = img_c\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.cord = cord\n",
    "        self.frames_n = frames_n\n",
    "        self.frames_cord = frames_cord\n",
    "        self.output_size = output_size\n",
    "        self.build()\n",
    "    \n",
    "    def build(self):\n",
    "        self.input_data = Input(name='the_input', shape=(77,50,100,3), dtype='float32')\n",
    "        \n",
    "        self.zero1 = ZeroPadding3D(padding=(1, 2, 2), name='zero1')(self.input_data)\n",
    "        self.conv1 = Conv3D(64, (3, 5, 5), strides=(1, 2, 2), kernel_initializer='he_normal', name='conv1')(self.zero1)\n",
    "        self.batc1 = BatchNormalization(name='batc1')(self.conv1)\n",
    "        self.actv1 = Activation('relu', name='actv1')(self.batc1)\n",
    "        self.drop1 = SpatialDropout3D(0)(self.actv1)\n",
    "        self.maxp1 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')(self.drop1)\n",
    "\n",
    "#         self.zero2 = ZeroPadding3D(padding=(1, 2, 2), name='zero2')(self.maxp1)\n",
    "#         self.conv2 = Conv3D(64, (3, 5, 5), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv2')(self.zero2)\n",
    "#         self.batc2 = BatchNormalization(name='batc2')(self.conv2)\n",
    "#         self.actv2 = Activation('relu', name='actv2')(self.batc2)\n",
    "#         self.drop2 = SpatialDropout3D(0)(self.actv2)\n",
    "#         self.maxp2 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')(self.drop2)\n",
    "\n",
    "#         self.zero3 = ZeroPadding3D(padding=(1, 1, 1), name='zero3')(self.maxp2)\n",
    "#         self.conv3 = Conv3D(96, (3, 3, 3), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv3')(self.zero3)\n",
    "#         self.batc3 = BatchNormalization(name='batc3')(self.conv3)\n",
    "#         self.actv3 = Activation('relu', name='actv3')(self.batc3)\n",
    "#         self.drop3 = SpatialDropout3D(0)(self.actv3)\n",
    "#         self.maxp3 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')(self.drop3)\n",
    "\n",
    "        #Residual conv2_x ouput 56x56x64 \n",
    "        self.x = Residual_Block(self.maxp1,nb_filter=64,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=64,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=64,kernel_size=(3,3,3))\n",
    "        \n",
    "        #Residual conv3_x ouput 28x28x128 \n",
    "        self.x = Residual_Block(self.x,nb_filter=128,kernel_size=(3,3,3),strides=(2,2,2),with_conv_shortcut=True)# need do convolution to add different channel\n",
    "        self.x = Residual_Block(self.x,nb_filter=128,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=128,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=128,kernel_size=(3,3,3))\n",
    "        \n",
    "        #Residual conv4_x ouput 14x14x256\n",
    "        self.x = Residual_Block(self.x,nb_filter=256,kernel_size=(3,3,3),strides=(2,2,2),with_conv_shortcut=True)# need do convolution to add different channel\n",
    "        self.x = Residual_Block(self.x,nb_filter=256,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=256,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=256,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=256,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=256,kernel_size=(3,3,3))\n",
    "        \n",
    "        #Residual conv5_x ouput 7x7x512\n",
    "        self.x = Residual_Block(self.x,nb_filter=512,kernel_size=(3,3,3),strides=(2,2,2),with_conv_shortcut=True)\n",
    "        self.x = Residual_Block(self.x,nb_filter=512,kernel_size=(3,3,3))\n",
    "        self.x = Residual_Block(self.x,nb_filter=512,kernel_size=(3,3,3))\n",
    "        \n",
    "        #Using AveragePooling replace flatten\n",
    "        self.x = AveragePooling3D()(self.x)\n",
    "\n",
    "        self.resh1 = TimeDistributed(Flatten())(self.x)\n",
    "\n",
    "        self.gru_1 = GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1')(self.resh1)\n",
    "        self.drop4 = Dropout(0)(self.gru_1)\n",
    "        self.gru_2 = GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2')(self.drop4)\n",
    "        self.drop5 = Dropout(0)(self.gru_2)\n",
    "\n",
    "        self.resh2 = Flatten()(self.drop5)\n",
    "        \n",
    "        self.input_cord = Input(name='the_input_cord', shape=(76,40), dtype='float32')\n",
    "        self.gru_3 = GRU(32, return_sequences=True, kernel_initializer='Orthogonal', name='gru3')(self.input_cord)\n",
    "        self.drop6 = Dropout(0)(self.gru_3)\n",
    "        self.gru_4 = GRU(32, return_sequences=True, kernel_initializer='Orthogonal', name='gru4')(self.drop6)\n",
    "        self.drop7 = Dropout(0)(self.gru_4)\n",
    "        \n",
    "        self.resh3 = Flatten()(self.drop7)\n",
    "        \n",
    "        self.z = Model(inputs = self.input_data, outputs = self.resh2) #\n",
    "        self.y = Model(inputs = self.input_cord, outputs = self.resh3) #\n",
    "        self.combined = layers.concatenate([self.z.output, self.y.output])\n",
    "        \n",
    "        # transforms RNN output to character activations:\n",
    "        self.dense1 = Dense(self.output_size, kernel_initializer='he_normal', name='dense1')(self.combined)\n",
    "\n",
    "        self.y_pred = Activation('softmax', name='softmax')(self.dense1)\n",
    "\n",
    "        self.model = Model(inputs = [self.input_data, self.input_cord], outputs = self.y_pred)\n",
    "        \n",
    "    def summary(self):\n",
    "        Model(inputs=[self.input_data, self.input_cord], outputs=self.y_pred).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_size = 200\n",
    "model = MODEL(img_c=3,img_w=100,img_h=50,cord=40,frames_n=77,frames_cord=76,output_size=len(tok.word_index))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复模型结构及权重\n",
    "# model.model.load_weights('./weight/CnnGRU_bright_BestWeights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam = Adam(lr=0.00001)\n",
    "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n",
    "#     \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n",
    "#     Arguments:\n",
    "#       target: A tensor of the same shape as `output`.\n",
    "#       output: A tensor resulting from a softmax\n",
    "#           (unless `from_logits` is True, in which\n",
    "#           case `output` is expected to be the logits).\n",
    "#       from_logits: Boolean, whether `output` is the\n",
    "#           result of a softmax, or is a tensor of logits.\n",
    "#       axis: Int specifying the channels axis. `axis=-1` corresponds to data\n",
    "#           format `channels_last', and `axis=1` corresponds to data format\n",
    "#           `channels_first`.\n",
    "#     Returns:\n",
    "#       Output tensor.\n",
    "#     Raises:\n",
    "#       ValueError: if `axis` is neither -1 nor one of the axes of `output`.\n",
    "#     \"\"\"\n",
    "\n",
    "#     rank = len(output.shape)\n",
    "#     axis = axis % rank\n",
    "#     # Note: nn.softmax_cross_entropy_with_logits_v2\n",
    "#     # expects logits, Keras expects probabilities.\n",
    "#     if not from_logits:\n",
    "#     # scale preds so that the class probas of each sample sum to 1\n",
    "#     output = output / math_ops.reduce_sum(output, axis, True)\n",
    "#     # manual computation of crossentropy\n",
    "#     epsilon_ = _to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "#     output = clip_ops.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "#     return -math_ops.reduce_sum(target * math_ops.log(output), axis)\n",
    "#     else:\n",
    "#     return nn.softmax_cross_entropy_with_logits_v2(labels=target, logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"./weight/ResnetGRU_cord_dif_GRU_32_normal.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.model.fit(x = [image_train, cord_train],\n",
    "                          y = label_train, \n",
    "                          validation_data = ([image_val, cord_val],label_val), \n",
    "                          epochs = 100, \n",
    "                          batch_size = minibatch_size, \n",
    "                          callbacks = [checkpoint], \n",
    "                          shuffle = True, \n",
    "                          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='center right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(history, \"acc\", \"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print中間層的output結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取某一层的输出为输出新建为model，采用函数模型\n",
    "layer_model = Model(inputs = model.input_data, outputs = model.model.get_layer('max1').output)\n",
    "\n",
    "#以这个model的预测值作为输出\n",
    "middle_output = layer_model.predict(image_train)\n",
    "print(middle_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(middle_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型结构及权重\n",
    "# model.model.save('./weight/CnnGRU_50_vocab.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复模型结构及权重\n",
    "model.model.load_weights('./weight/ResnetGRU_cord_dif_GRU_32_normal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.model.predict([image_val, cord_val])           # predict result is value\n",
    "# temp = model.model.predict_classes(image_val)     # predict class, but only use model = Sequential() format\n",
    "predict = np.argmax(predict,axis=1)\n",
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(predict)):\n",
    "    temp = labels_to_text([predict[i]])\n",
    "    result.append(temp)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in result:\n",
    "#     print('Predict label:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in txt_val:\n",
    "#     print('True label:', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = split_word\n",
    "print(classification_report(txt_val, result, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = model.model.evaluate(image_train, label_train)\n",
    "print ('\\ntrain Acc:', train_acc[1])\n",
    "\n",
    "val_acc = model.model.evaluate(image_val, label_val)\n",
    "print ('\\nTest Acc:', val_acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
